cluster:
  clusterid: "ceph"
  use_existing: True
  head: "root@gprfc073"
  clients: ["root@gprfc073"]
  osds: ["root@gprfc073"]
  mons: ["root@gprfc073"]
  osds_per_node: 1
#  fs: xfs
#  mkfs_opts: -f -i size=2048
#  mount_opts: -o inode64,noatime,logbsize=256k
  conf_file: /etc/ceph/ceph.conf
  ceph.conf: /etc/ceph/ceph.conf
  iterations: 1
  rebuild_every_test: False
  tmp_dir: "/tmp/cbt"
  osd_ra: 4096
  pool_profiles:
    replicated:
      size: 1
      min_size: 1
      # pg = placement groups
      #pg_size: 4096
      #pgp_size: 4096
      replication: 1
    karl-pool:
      pg_size: 256
      pgp_size: 256
      replication: 1
benchmarks:
  librbdfio:
    time: 10
    vol_size: 2048
    mode: ['read', 'write', 'randread', 'randwrite', 'rw', 'randrw']
    rwmixread: 50
    op_size: [4194304, 131072, 4096]
    procs_per_volume: [1] 
    volumes_per_client: [1] 
    iodepth: [32]
    osd_ra: [4096]
    cmd_path: '/root/fio.axboe/fio'
    pool_profile: 'karl-pool'
    log_avg_msec: 100 

# radosbench:
#   op_size: [ 4194304, 524288, 4096 ]
#   write_only: False
#   time: 30
#   concurrent_ops: [ 128 ]
#   concurrent_procs: 1
#   use_existing: True
#   pool_profile: replicated
#
